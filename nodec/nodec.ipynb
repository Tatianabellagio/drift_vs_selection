{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0690ecff-ea6d-426d-a568-8eaf26c20756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once i have wholegenome_offset.trees\n",
    "import pandas as pd\n",
    "import tskit\n",
    "import allel\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tsinfer\n",
    "import pyslim\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4ee826-d0ca-480a-958a-025833265e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_neutral_mut (ts_new, ts, mapper_realid_metadataid):\n",
    "    ## extract surviving ndoes and comapre them to our old ndoes to place mtuations in the right place\n",
    "    surviving_nodes = []\n",
    "    for i in ts_new.tables.nodes:\n",
    "        surviving_nodes.append(i.metadata['slim_id'])\n",
    "    ## new nodes id and the ids i gave them in the past\n",
    "    new_mapper = pd.DataFrame({'new_ids': range(0, len(ts_new.tables.nodes)), 'my_ids_metadata':surviving_nodes})\n",
    "    ## map old nodes with new nodes\n",
    "    mapper_lost_nodes = new_mapper.merge(mapper_realid_metadataid, left_on = 'my_ids_metadata', right_on = 'my_ids_metadata', how= 'right')\n",
    "\n",
    "    ## create a mask to only keep from the old nodes the ones that survived the simulation\n",
    "    mask = mapper_lost_nodes['new_ids'].notna()\n",
    "\n",
    "    tables_og = ts.dump_tables()\n",
    "\n",
    "    ## now filter old tables only based on surviving nodes \n",
    "    tables_og.nodes.replace_with(tables_og.nodes[mask])\n",
    "\n",
    "    ## now filter mutation table based on the surviving nodes, for that, extract the nodes \n",
    "    old_nodes = tables_og.mutations.node\n",
    "\n",
    "    old_nodes = pd.Series(old_nodes)\n",
    "\n",
    "    old_nodes.name = 'old_nodes'\n",
    "\n",
    "    ## create a dataframe relating the new and old nodes\n",
    "    replace_oldbynew_nodes = pd.merge(old_nodes, mapper_lost_nodes, left_on ='old_nodes', right_on = 'real_id', how= 'left')\n",
    "\n",
    "    ## create a mask to filter out all the mutations than has been lost \n",
    "    mask_mutations_lost = replace_oldbynew_nodes['new_ids'].notna()\n",
    "\n",
    "    ## filter out mutations that has been lost \n",
    "    table_mutations = tables_og.mutations[mask_mutations_lost]\n",
    "\n",
    "    ## now replace the old nodes ids by the new nodes ids with the mapper\n",
    "    ids_to_replace = replace_oldbynew_nodes.dropna()['new_ids']\n",
    "    table_mutations.node = np.array(ids_to_replace.astype('int32'))\n",
    "\n",
    "    ## and jsut set the sites from 0 to the length of mutation table \n",
    "    table_mutations.site = np.array(range(0, len(table_mutations))).astype('int32')\n",
    "\n",
    "    ## apply the same filter from the mutations table to the sites table \n",
    "    table_sites = tables_og.sites[mask_mutations_lost]  \n",
    "\n",
    "    ## now replace all this filter old tables in the new tree seq! \n",
    "    new_tables = ts_new.dump_tables()\n",
    "\n",
    "    new_tables.mutations.replace_with(table_mutations)\n",
    "\n",
    "    new_tables.sites.replace_with(table_sites)\n",
    "\n",
    "    ## make sure to compure mutations parents\n",
    "    new_tables.compute_mutation_parents()\n",
    "\n",
    "    ## create tree seq based on tables\n",
    "    tree_nm = new_tables.tree_sequence()\n",
    "\n",
    "    return tree_nm.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e090377c-f483-4208-a2f4-9882098fb265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tree_to_vcf (tree,name_vcf):\n",
    "    # create a vcf file from the treeseq \n",
    "    with open(name_vcf, 'w') as file:\n",
    "        # Pass the file object as the output parameter\n",
    "        tree.write_vcf(output=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d511977c-8049-4d82-9032-0cbcd776a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the old tree\n",
    "ts_old = tskit.load(\"../../treeseq/wholegenome_offset_baselinetree.trees\")\n",
    "#import mapper old nodes to new nodes\n",
    "mapper_realid_metadataid = pd.read_csv('../../treeseq/mapper_realid_metadataid_wholegenome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e79d82af-9b25-4242-a222-4dffc594f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfing = tskit.load('drift_nocrossin_norec1_result.trees')\n",
    "\n",
    "ts_nm = overlap_neutral_mut(selfing, ts_old, mapper_realid_metadataid)\n",
    "\n",
    "convert_tree_to_vcf(ts_nm, f'selfing.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610591a5-1795-4cb2-a612-72fc3e08fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fba962-6ddd-4bca-a737-65e8f7a2248e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4c3c9d-249c-495e-8c7d-b850abb3f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_drift_norecomb = allel.read_vcf(f'selfing.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be0462c-4143-4527-b5ba-fa5d6beb875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vcf_drift_norecomb['samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2395ef48-8def-4101-a012-e98217368f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_drift_no_recomb = vcf_drift_norecomb[\"calldata/GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185be117-8b92-410b-b4d0-9621a1998f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_al_per_pos_nr = geno_drift_no_recomb.sum(axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7a2e8a-ae2b-4789-addc-113210521465",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_al_per_pos_nr = np.swapaxes(alt_al_per_pos_nr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94825d48-270e-4df3-bc7c-acdc7f95811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count ecotypes \n",
    "genotpye_counts = {}\n",
    "for i in alt_al_per_pos_nr:\n",
    "    sample = i.tobytes()\n",
    "    if sample in genotpye_counts:\n",
    "        genotpye_counts[sample] += 1\n",
    "    else:\n",
    "        genotpye_counts[sample] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da9cbfa-6f15-4dac-a123-fe153fe3d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3hundred something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb0bea4-3c50-4384-8198-3f73af1d87e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genotpye_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a816cee-41ed-42e8-8ff9-6825faa57899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3, 3, 3, 7, 4, 3, 2, 6, 5, 5, 1, 4, 4, 4, 6, 3, 1, 1, 7, 1, 3, 4, 5, 3, 3, 4, 2, 3, 1, 5, 7, 5, 1, 4, 3, 2, 6, 3, 6, 6, 1, 7, 4, 2, 2, 3, 1, 3, 3, 3, 2, 5, 4, 3, 5, 3, 2, 7, 1, 5, 11, 3, 4, 1, 2, 1, 2, 1, 5, 3, 1, 3, 4, 8, 8, 3, 2, 5, 2, 5, 2, 4, 1, 7, 1, 6, 3, 3, 3, 1, 3, 8, 2, 2, 1, 4, 4, 1, 4, 3, 6, 1, 3, 2, 4, 2, 1, 3, 2, 5, 1, 7, 3, 2, 4, 3, 1, 3, 7, 3, 1, 2, 8, 2, 1, 1, 4, 1, 1, 10, 1, 2, 3, 2, 7, 2, 2, 6, 4, 1, 1, 1, 3, 2, 1, 4, 2, 4, 4, 1, 3, 2, 4, 5, 2, 6, 1, 1, 9, 3, 1, 6, 1, 2, 3, 5, 1, 7, 1, 2, 3, 1, 2, 2, 2, 7, 4, 3, 4, 2, 3, 5, 7, 4, 3, 5, 2, 2, 5, 1, 1, 2, 3, 6, 1, 2, 4, 3, 1, 2, 2, 1, 1, 2, 1, 3, 3, 4, 1, 1, 1, 4, 1, 4, 1, 2, 2, 1, 1, 3, 2, 4, 7, 1, 6, 3, 1, 2, 1, 3, 4, 5, 3, 2, 2, 1, 2, 2, 2, 1, 1, 4, 1, 1, 1, 2, 2, 2, 2, 5, 2, 2, 2, 3, 2, 3, 2, 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 5, 1, 4, 1, 1, 3, 1, 4, 3, 3, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genotpye_counts.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d946a-feea-4b1c-8bc7-4d5b1f1181c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
